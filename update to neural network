import tensorflow
import numpy as np
import tensorflow as tf
from tensorflow import keras
import pandas as pd
from tensorflow.keras import layers
import matplotlib.pyplot as plt 
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Dense 
from tensorflow.keras.losses import SparseCategoricalCrossentropy
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
# %%
#reading in the data:
file_path="/Users/blenl/Desktop/data_file.csv"
df = pd.read_csv(file_path)
print (df.head())

# %%
#defininng training sets to be 60% of the data and reshaping for use with tensorflow:
x_train=df.iloc[0:3619,2:5]
y_train = df.iloc[0:3619, 5].values
# %%
#Feature Scaling to get the data on different columns near similar values:
scaler=StandardScaler()
x_train=scaler.fit_transform(x_train)
# %%
#defining the model using sequential:
model= Sequential ([
    Dense (units=30, activation='relu'),
    Dense (units=15, activation='relu'),
    Dense (units=1, activation='linear')
    ])

# %%
#compiling:
model.compile (optimizer='adam', loss='mse', metrics=['mae'])

# %%
#fitting 
#specifying batch=32 makes it so that after each epoch, it calculates the cost 
#providing a separate validation set allows for the checking of how well the model is doing  
history= model.fit(x_train, y_train, epochs=100, batch_size=32, validation_split=0.2)
# %%
#Making predictions:
y_hat = model.predict(x_train)  # shape will be (n_samples, 1)
#y_hat represents the final values gained from the model.
# Flatten the values to a 1D array:
y_hat = y_hat.flatten()
# %%
#Extracting metrics:
mae= history.history["mae"]
loss= history.history["loss"]
val_mae= history.history["val_mae"]
val_loss= history.history ["val_loss"]

end_mae = mae[-1]
end_loss = loss[-1]
end_val_mae = val_mae[-1]
end_val_loss = val_loss[-1]

print("The Accuracy of model is", end_mae, "and the loss is", end_loss)
print ("The Validation accuracy is", end_val_mae, "and the validation loss is", end_val_loss)
# %%
#plotting actual(y_train) v expected (y_hat) to visually asses success of model:
plt.scatter (y_train, y_hat)
plt.xlabel("Actual Molecular Weight (g/mol)")
plt.ylabel("Predicted Molecular Weight (g/mol)")
#The trend of following the y=x line means the model is performing well and can move on to being tested by the testing data
